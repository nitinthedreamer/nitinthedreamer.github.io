<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Nitin Kumar</title> <meta name="author" content="Nitin Kumar"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nitinthedreamer.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Research</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Nitin</span> Kumar </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.png?0dad7b693805a24cdc53b33aa780847d" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="prof_pic.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p><a href="/assets/pdf/nitin_resume_research.pdf">CV</a> | <a href="linkedin.com/in/nitinthedreamer">LinkedIn</a> | <a href="github.com/nitinthedreamer">Github</a></p> <p>I am a Master’s Student (Research) in Computer Science at University of Colorado, Boulder advised by <a href="https://www.colorado.edu/ics/leanne-hirshfield" rel="external nofollow noopener" target="_blank">Leanne Hirshfield</a> working as Research Assistant in <a href="https://www.shinelaboratory.com" rel="external nofollow noopener" target="_blank">System-Human Interaction with NIRS and EEG (SHINE) Lab</a>. My Research areas include Deep learning architectures, Neuroscience, Human-Agent Teaming, NLP and Neuro-inspired AI architectures.</p> <p>Prior to this, I worked as Software Development Engineer II at <a href="https://www.aboutamazon.com" rel="external nofollow noopener" target="_blank">Amazon</a>, India for 4+ years designing and developing software products. I completed my Bachelor’s in Computer Science and Engineering from <a href="https://www.iitrpr.ac.in" rel="external nofollow noopener" target="_blank">Indian Institute of Technology, Ropar</a> in 2017.</p> <p>Outside of work, I am a hindustani classical trained singer and like playing musical instruments like Guitar, Piano. I also like to play card games and billiards. In my outdoor time, I like to hike and explore nature.</p> </div> <h2><a href="/news/" style="color: inherit;">Updates</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jun, 2022</th> <td> Joined Shine Lab, working under Prof. Leanne Hirshfield, as a Research Assistant. </td> </tr> <tr> <th scope="row">Aug, 2021</th> <td> Joined University of Colorado, Boulder as Masters Student in Computer Science. </td> </tr> <tr> <th scope="row">Oct, 2020</th> <td> Promoted to Software Development Engineer II at Amazon, Hyderabad. </td> </tr> <tr> <th scope="row">Aug, 2017</th> <td> Joined Amazon, Hyderabad as Software Development Engineer I. </td> </tr> <tr> <th scope="row">May, 2017</th> <td> Graduated from Indian Institute of Technology, Ropar with major in Computer Science and Engineering. </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">Selected Research</a></h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/Speech%20HAT-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/Speech%20HAT-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/Speech%20HAT-1400.webp"></source> <img src="/assets/img/publication_preview/Speech%20HAT.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="Speech HAT.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Human Agent Teaming" class="col-sm-8"> <div class="title">Using Speech Patterns to Model the Dimensions of Teamness in Human-Agent Teams</div> <div class="author"> <a href="https://www.colorado.edu/ics/emily-doherty" rel="external nofollow noopener" target="_blank">Emily Doherty</a>, <a href="https://www.colorado.edu/ics/cara-spencer-0" rel="external nofollow noopener" target="_blank">Cara A Spencer</a>, <a href="https://www.luccaoeloy.com" rel="external nofollow noopener" target="_blank">Lucca Eloy</a>, Nitin Kumar*, Rachel Dickler, and <a href="https://www.colorado.edu/ics/leanne-hirshfield" rel="external nofollow noopener" target="_blank">Leanne Hirshfield</a> </div> <div class="periodical"> <em>ICMI ’23: Proceedings of the 25th International Conference on Multimodal Interaction</em>, Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://dl.acm.org/doi/pdf/10.1145/3577190.3614121" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="https://doi.org/10.1145/3577190.3614121"></span> <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1145/3577190.3614121" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Teamness is a newly proposed multidimensional construct aimed to characterize teams and their dynamic levels of interdependence over time. Specifically, teamness is deeply rooted in team cognition literature, considering how a team’s composition, processes, states, and actions affect collaboration. With this multifaceted construct being recently proposed, there is a call to the research community to investigate, measure, and model dimensions of teamness. In this study, we explored the speech content of 21 human-human-agent teams during a remote collaborative search task. Using self-report surveys of their social and affective states throughout the task, we conducted factor analysis to condense the survey measures into four components closely aligned with the dimensions outlined in the teamness framework: social dynamics and trust, affect, cognitive load, and interpersonal reliance. We then extracted features from teams’ speech using Linguistic Inquiry and Word Count (LIWC) and performed Epistemic Network Analyses (ENA) across these four teamwork components as well as team performance. We developed six hypotheses of how we expected specific LIWC features to correlate with self-reported team processes and performance, which we investigated through our ENA analyses. Through quantitative and qualitative analyses of the networks, we explore differences of speech patterns across the four components and relate these findings to the dimensions of teamness. Our results indicate that ENA models based on selected LIWC features were able to capture elements of teamness as well as team performance; this technique therefore shows promise for modeling of these states during CSCW, to ultimately design intelligent systems to promote greater teamness using speech-based measures.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/DDPM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/DDPM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/DDPM-1400.webp"></source> <img src="/assets/img/publication_preview/DDPM.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="DDPM.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Generative AI" class="col-sm-8"> <div class="title">Image Defogging Using Conditional Denoising Diffusion Probabilistic Models (DDPMs)</div> <div class="author"> Nitin Kumar, Nidhin Harilal, and Tushar Gautam</div> <div class="periodical"> May 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Diffusion_Defogging__5822_Project_Report.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Fog and haze have long been detrimental factors in obtaining clear and high-quality images, significantly affecting computer vision and image processing applications. Traditional single- image defogging methods often rely on the physical scattering model or utilize machine learning-based techniques. However, these methods have been plagued with limitations, such as the inability to recover fine details, susceptibility to noise, and poor generalization. In this paper, we propose a novel single-image defogging method based on the denoising diffusion probabilistic model, which addresses the shortcomings of existing techniques. Our experiments on Cityscapes benchmark dataset show promising results.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/COAT-DQN-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/COAT-DQN-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/COAT-DQN-1400.webp"></source> <img src="/assets/img/publication_preview/COAT-DQN.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="COAT-DQN.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Deep RL" class="col-sm-8"> <div class="title">CoAt-DQN: Convolution and Attention Deep Q-Network</div> <div class="author"> Nitin Kumar, and Seonwoo Kim</div> <div class="periodical"> Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/CoAt_DQN_Final_Report.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Post the advent of Deep Q-Learning, which has been successful in solving Reinforcement learning problems with ease and becoming a state of the art technique, it still had issues in how the agent views the world. The underlying model encoding the visual world ie. CNN, has not been able to model the non- local pixels well leading to misses in these relationships. We present an architecture CoAt-DQN which combines CNNs with Transformers by combining attention with convolution and stacking of the individual layers in relevant fashion enabling the advantages of generalization and attention leading to network with better approximation of the Q-values for different actions and the given state, leading to better policies with the improve- ments making the agent view the world better. We showcase the reward improvements using Atari Breakout game leading to huge performance improvements especially after 10,000 episodes. We compare the reward outputs with our baseline models DQN and Dueling DQN. Our model, CoAt- DQN shows the fastest improvement and achieves the highest score among the models with 60.8 as its best score for Breakout in 10,000 episode training. Further, We also train our CoAt- DQN model with different batch sizes of 32, 128 and 1024 to further optimize the model. We observe similar performances w.r.t. rewards but training time decreases with increase in batch size.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/reverse_dict-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/reverse_dict-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/reverse_dict-1400.webp"></source> <img src="/assets/img/publication_preview/reverse_dict.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="reverse_dict.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="NLP" class="col-sm-8"> <div class="title">Neural Multi-Channel Reverse Dictionary</div> <div class="author"> Nitin Kumar, and Rohan Das</div> <div class="periodical"> May 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/Neural%20Multi-channel%20reverse%20dictionary%20Report.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>A reverse dictionary is a system that lets a user search for words based on their description or definition. Reverse Dictionaries have practi- cal benefits in solving the “tip of the tongue’ problem besides being a teaching tool for new language learners. Existing solutions for the re- verse dictionary problem are unable to account for the high variability in the user descriptions and don’t do well when it comes to predict- ing infrequently used words. Moreover, such systems use context free embeddings to encode the descriptions thus ignoring the semantic rela- tionships between the words in the description. We propose a neural reverse dictionary model with linguistic predictors, inspired from how humans infer words from descriptions. Our model uses contextualized embeddings from RoBERTa along with multiple linguistically motivated channel predictors that aim to over- come the issues of sparsity and polysemy. We see very encouraging results that highlight the importance of contextualized embeddings and the grounding of natural language models in linguistic theory.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/neuron-3d-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/neuron-3d-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/neuron-3d-1400.webp"></source> <img src="/assets/img/publication_preview/neuron-3d.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="neuron-3d.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="NLR" class="col-sm-8"> <div class="title">3D Single Neuron Reconstruction</div> <div class="author"> Shubham Sharma, Nitin Kumar, and Saurabh Khoria</div> <div class="periodical"> May 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/BTP%20Report.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p> Analysing neuron structure is critical for understanding how they function within neural circuits. Neuron tracing or Neuron reconstruction is a technique used in computational neuroscience to determine the path of neural axons and dendrites from advanced microscopic images. Due to the high complexity of neuron morphology and often seen heavy noise in such images, as well as the typically encountered massive amount of image data, it has been widely viewed as one of the most challenging computational tasks for computational neuroscience. The goal of this project is to develop a completely automatic method for tracing the neuron morphology in 3D. Neuron reconstruction is critical to understanding the neuron anatomy. By understanding the single neuron anatomy, it becomes easier to understand the how a particular neuron is connected to other neurons. This also helps us to better understand certain properties like cell-firing etc. Also, knowing the right morphology of the neuron helps us to analyse what changes are seen in its structure with age and certain conditions like stress or disease etc. </p> </div> </div> </div> </li></ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6E%69%74%69%6E.%6B%75%6D%61%72-%31@%63%6F%6C%6F%72%61%64%6F.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> You can even add a little note about which of these is the best way to reach you. </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Nitin Kumar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>